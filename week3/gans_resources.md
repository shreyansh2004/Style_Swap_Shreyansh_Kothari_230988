# Week3

These resources are some of the basic resources that can help you guys start with GANs so that you can venture out the seas of the internet and understand what a GAN article/paper or code is trying to convey.

---

### GANs

- [GANs paper](https://arxiv.org/pdf/1406.2661)
- A very intuitive [playlist](https://youtube.com/playlist?list=PLZsOBAyNTZwboR4_xj-n3K6XBTweC4YVD&si=iQp351Fp0Ijx6iEF) on GANs, can look up his channel too great content on very basic and niche parts of ML
- Chapter 20 from [d2l](https://d2l.ai)
- Probably the best GAN [medium article](https://towardsdatascience.com/understanding-generative-adversarial-networks-gans-cd6e4651a29)
- [Training a basic GAN using pytorch](https://jovian.ai/aakashns/06b-anime-dcgan)

After this material, you can take up a GAN paper like pix2pix and try to understand it.

---

### GANs inversion

GAN inversion aims to invert a given image back into the latent space of a pretrained GAN model so that the image can be reconstructed from the inverted code by the generator.

- [Paper](https://arxiv.org/pdf/2101.05278)
- A medium [blog series](https://sertiscorp.medium.com/gan-inversion-a-brief-walkthrough-part-i-bc2ee1b73253) explaining GAN inversion in detail
- [ะต4ะต Explained](https://www.casualganpapers.com/stylegan-encoder-latent-projection-gan-inversion-image-editing/e4e-explained.html)

---

> The problem with GAN is that the devil is in the details. The hyper parameters, the training loop and a plethora of tricks will make it go from ugly to good while having the exact same network architecture behind it.
> I personally learned most of it by directly looking at other people's code, articles, reddit comments
> ~ some random guy on reddit
